# Placement: Colocate â€” All pods on a single node
# Combined with pod-delete on checkoutservice to measure recovery under
# maximum resource contention (CPU, memory, IO all shared on one node).
#
# Usage:
#   1. Deploy online-boutique first:
#      uv run chaosprobe provision scenarios/online-boutique/deploy/
#   2. Apply colocate placement:
#      uv run chaosprobe placement apply colocate -n online-boutique
#   3. Run this experiment:
#      uv run chaosprobe run scenarios/online-boutique/placement-colocate/ -o colocate-results.json
#
# Hypothesis: Recovery will be slowest because the rescheduled pod competes
# with all other services for the same node's resources.
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: placement-colocate-pod-delete
spec:
  engineState: active
  appinfo:
    appns: online-boutique
    applabel: app=checkoutservice
    appkind: deployment
  chaosServiceAccount: litmus-admin
  experiments:
    - name: pod-delete
      spec:
        components:
          env:
            - name: TOTAL_CHAOS_DURATION
              value: "120"
            - name: CHAOS_INTERVAL
              value: "20"
            - name: FORCE
              value: "true"
            - name: PODS_AFFECTED_PERC
              value: "100"
        probe:
          - name: frontend-availability
            type: httpProbe
            mode: Continuous
            httpProbe/inputs:
              url: http://frontend.online-boutique.svc.cluster.local
              method:
                get:
                  criteria: ==
                  responseCode: "200"
            runProperties:
              probeTimeout: 10s
              interval: 5s
              retry: 3
