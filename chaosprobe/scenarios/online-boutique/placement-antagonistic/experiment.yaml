# Placement: Antagonistic â€” Resource-heavy pods packed on same node
# Combined with pod-delete on checkoutservice to measure recovery when
# the heaviest services (adservice, loadgenerator, recommendationservice,
# cartservice, etc.) are all on the same node as checkout.
#
# Usage:
#   1. Deploy online-boutique first:
#      uv run chaosprobe provision scenarios/online-boutique/deploy/
#   2. Apply antagonistic placement:
#      uv run chaosprobe placement apply antagonistic -n online-boutique
#   3. Run this experiment:
#      uv run chaosprobe run scenarios/online-boutique/placement-antagonistic/ -o antagonistic-results.json
#
# Hypothesis: Recovery will be worst because the rescheduled pod must
# compete with the heaviest workloads for IO, CPU, and memory.
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: placement-antagonistic-pod-delete
spec:
  engineState: active
  appinfo:
    appns: online-boutique
    applabel: app=checkoutservice
    appkind: deployment
  chaosServiceAccount: litmus-admin
  experiments:
    - name: pod-delete
      spec:
        components:
          env:
            - name: TOTAL_CHAOS_DURATION
              value: "120"
            - name: CHAOS_INTERVAL
              value: "20"
            - name: FORCE
              value: "true"
            - name: PODS_AFFECTED_PERC
              value: "100"
        probe:
          - name: frontend-availability
            type: httpProbe
            mode: Continuous
            httpProbe/inputs:
              url: http://frontend.online-boutique.svc.cluster.local
              method:
                get:
                  criteria: ==
                  responseCode: "200"
            runProperties:
              probeTimeout: 10s
              interval: 5s
              retry: 3
